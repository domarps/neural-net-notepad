{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cgan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/domarps/neural-net-notepad/blob/master/cgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0oYHyOYLZeTD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import torch.nn.functional as nn\n",
        "import torch.autograd as autograd\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDTNOdSWZfZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "fdcaeaa8-49e6-45cb-a66c-a12d0f596d2e"
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-6fc50b429ca7>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o0RIVsEzZoYX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9661d74a-002a-4e2f-dee2-3a2d98f9be41"
      },
      "cell_type": "code",
      "source": [
        "X_dim, y_dim = mnist.train.images.shape[1], mnist.train.labels.shape[1] # X (image dimension), y (label dimension)\n",
        "print(X_dim, y_dim)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KPSS_0qSZ6sR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Z_dim = 100\n",
        "h_dim = 128\n",
        "cnt = 0\n",
        "lr = 1e-3\n",
        "mini_batch = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SiTHhgkpapTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    w = torch.empty(*size)\n",
        "    return torch.nn.init.xavier_normal_(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RPp6L_WxbybD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" ==================== GENERATOR ======================== \"\"\"\n",
        "\n",
        "Whx = xavier_init(size=[h_dim, X_dim])\n",
        "bhx = torch.zeros(X_dim, requires_grad=True)\n",
        "\n",
        "Wzh = xavier_init(size=[Z_dim + y_dim, h_dim])\n",
        "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
        "                  \n",
        "\n",
        "def G(z, c):\n",
        "    inputs = torch.cat([z, c], 1)\n",
        "    h = nn.relu(inputs @ Wzh + bzh.repeat(inputs.size(0), 1))\n",
        "    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
        "    return X\n",
        "\n",
        "\n",
        "  \n",
        "\"\"\" ==================== DISCRIMINATOR ======================== \"\"\"\n",
        "\n",
        "Wxh = xavier_init(size=[X_dim + y_dim, h_dim])\n",
        "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
        "\n",
        "Why = xavier_init(size=[h_dim, 1])\n",
        "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
        "\n",
        "def D(X, c):\n",
        "  inputs = torch.cat([X, c], 1)\n",
        "  h = nn.relu(inputs @ Wxh + bxh.repeat(inputs.size(0), 1))\n",
        "  y = nn.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BN4nnDQxbzlz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "G_params = [Wzh, bzh, Whx, bhx]\n",
        "D_params = [Wxh, bxh, Why, bhy]\n",
        "params = G_params + D_params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nqtJR3B_c1db",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" ===================== TRAINING ======================== \"\"\"\n",
        "\n",
        "\n",
        "def reset_grad():\n",
        "    for p in params:\n",
        "        if p.grad is not None:\n",
        "            data = p.grad.data\n",
        "            p.grad = Variable(data.new().resize_as_(data).zero_())\n",
        "\n",
        "\n",
        "G_solver = optim.Adam(G_params, lr=1e-3)\n",
        "D_solver = optim.Adam(D_params, lr=1e-3)\n",
        "\n",
        "ones_label = Variable(torch.ones(mini_batch, 1))\n",
        "zeros_label = Variable(torch.zeros(mini_batch, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wsx_cFLzeN9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ccd16ae0-c40c-4175-b024-93c36bae0a4c"
      },
      "cell_type": "code",
      "source": [
        "for it in range(10):\n",
        "    # Sample data\n",
        "    z = Variable(torch.randn(mini_batch, Z_dim))\n",
        "    X, c = mnist.train.next_batch(mini_batch)\n",
        "    X = Variable(torch.from_numpy(X))\n",
        "    c = Variable(torch.from_numpy(c.astype('float32')))\n",
        "\n",
        "    # Dicriminator forward-loss-backward-update\n",
        "    G_sample = G(z, c)\n",
        "    D_real = D(X, c)\n",
        "    D_fake = D(G_sample, c)\n",
        "\n",
        "    D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
        "    D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
        "    D_loss = D_loss_real + D_loss_fake\n",
        "\n",
        "    D_loss.backward()\n",
        "    D_solver.step()\n",
        "\n",
        "    # Housekeeping - reset gradient\n",
        "    reset_grad()\n",
        "\n",
        "    # Generator forward-loss-backward-update\n",
        "    z = Variable(torch.randn(mini_batch, Z_dim))\n",
        "    G_sample = G(z, c)\n",
        "    D_fake = D(G_sample, c)\n",
        "\n",
        "    G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
        "\n",
        "    G_loss.backward()\n",
        "    G_solver.step()\n",
        "\n",
        "    # Housekeeping - reset gradient\n",
        "    reset_grad()\n",
        "\n",
        "    # Print and plot every now and then\n",
        "    if it % 2 == 0:\n",
        "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
        "\n",
        "        c = np.zeros(shape=[mini_batch, y_dim], dtype='float32')\n",
        "        c[:, np.random.randint(0, 10)] = 1.\n",
        "        c = Variable(torch.from_numpy(c))\n",
        "        samples = G(z, c).data.numpy()[:16]\n",
        "\n",
        "        fig = plt.figure(figsize=(4, 4))\n",
        "        gs = gridspec.GridSpec(4, 4)\n",
        "        gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "        for i, sample in enumerate(samples):\n",
        "            ax = plt.subplot(gs[i])\n",
        "            plt.axis('off')\n",
        "            ax.set_xticklabels([])\n",
        "            ax.set_yticklabels([])\n",
        "            ax.set_aspect('equal')\n",
        "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "        if not os.path.exists('out/'):\n",
        "            os.makedirs('out/')\n",
        "\n",
        "        plt.savefig('out/{}.png'.format(str(cnt).zfill(3)), bbox_inches='tight')\n",
        "        cnt += 1\n",
        "        plt.close(fig)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter-0; D_loss: 1.418475866317749; G_loss: 0.5838829874992371\n",
            "Iter-2; D_loss: 1.4518413543701172; G_loss: 0.5999220013618469\n",
            "Iter-4; D_loss: 1.4239389896392822; G_loss: 0.6015939116477966\n",
            "Iter-6; D_loss: 1.446860909461975; G_loss: 0.5961887836456299\n",
            "Iter-8; D_loss: 1.3827154636383057; G_loss: 0.5864787697792053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "73GrfczLeWmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c45b89a3-707c-4449-e24c-93042f406ef5"
      },
      "cell_type": "code",
      "source": [
        "! ls out/"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "000.png  001.png  002.png  003.png  004.png  005.png  006.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K2GP5w0Ue151",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}